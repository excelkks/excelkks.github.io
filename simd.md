
类型转换

有一些指令用于进行类型转换，它们只支持带符号的 32 位整数通道（lane）。
	•	_mm_cvtepi32_ps：将 4 个 32 位整数转换为 32 位浮点数；
	•	_mm_cvtepi32_pd：将前 2 个整数转换为 64 位浮点数；
	•	_mm256_cvtpd_epi32：将 4 个 64 位双精度浮点数转换为 4 个整数，同时将输出的高 4 个通道清零。

从浮点数转换为整数时，这些指令会使用 MXCSR 控制与状态寄存器中指定的舍入模式。要修改该模式，可使用 _MM_SET_ROUNDING_MODE 宏。
需要注意的是，这个模式值是线程状态的一部分，操作系统会在上下文切换时保存该值。

还有一些带有额外的 “t” 的指令（如 _mm_cvttpd_epi32 和 _mm_cvttps_epi32），它们会忽略 MXCSR 设置，始终使用**向零截断（truncation towards zero）**的舍入方式。

此外，还有一些指令支持在 32 位和 64 位浮点数之间进行转换。

⸻

内存访问

将数据从内存加载到寄存器的方式有很多：
	•	所有类型都支持常规对齐加载，如 _mm_load_si128 或 _mm256_load_ps，要求源地址分别按 16 字节或 32 字节对齐。否则可能会崩溃，具体取决于编译器设置。
	•	所有类型也都支持非对齐加载，如 _mm_loadu_si128 或 _mm256_loadu_ps，可以用于非对齐指针，但对齐加载的性能更好。
	•	__m128 和 __m128d 类型还支持一些额外操作：
	•	单通道加载，只加载第一个通道，其他通道置为 0（如 _mm_load_ss 和 _mm_load_sd）；
	•	反向顺序加载（需要对齐的源地址）。
	•	在 AVX 中，__m128、__m256 和 __m256d 类型支持广播加载指令，可以从内存中加载一个浮点数或双精度数，并复制到目标变量的所有通道。
	•	__m256 和 __m256d 也有广播加载，读取 16 字节并复制到目标寄存器的两半部分。
	•	AVX1 引入了掩码加载指令，可以选择性地加载某些通道，其余通道清零。
	•	AVX2 引入了gather 加载指令，如 _mm_i32gather_ps，接收一个基地址、一个包含偏移量的整数寄存器，以及一个用于缩放偏移的整数值。虽然实用，但速度较慢。
	•	实际中，很多时候你并不需要特殊指令加载数据。例如，如果源数据是对齐的，可以直接使用如下代码：

__m128i value = *pointer;

编译器会将其编译为等价的普通加载指令。

⸻

存储方式也有很多种：

包括对齐、非对齐、单通道、AVX1 中的掩码存储等。

⸻

关于 RAM 访问的一些通用说明：
	1.	在现代 PC 中，内存每次至少传输 8 字节，如果使用双通道内存，则每次可传输 16 字节。因此，以对齐的 16 或 32 字节块访问内存的效率更高。
	2.	如果你查看现代 memcpy 或 memmove 函数的源码，通常会发现使用 SSE2 指令手动向量化的实现，用来快速复制内存。
	3.	需要对数据进行转置时，也建议先连续加载 16 或 32 字节的块，然后在寄存器中使用 shuffle 指令转置，效率更高。
	4.	许多指令支持以内存作为其中一个操作数：
	•	编译目标为 SSE 时，要求加载地址必须对齐；
	•	编译目标为 AVX 时，既支持对齐也支持非对齐；
	•	例如：

_mm_add_ps(v, _mm_loadu_ps(ptr)); // 仅在 AVX 编译下合并加载和加法
_mm_add_ps(v, _mm_load_ps(ptr));  // 所有平台都合并，但非对齐地址可能导致运行时崩溃


	5.	多数单通道加载/存储只能使用目标/源寄存器的最低通道。如果你在实现如求和或平均等归约操作，建议将结果最终放在第一个通道中。
	6.	有一些 AVX 指令（如 _mm256_insertf128_ps、_mm256_insertf128_pd、_mm256_inserti128_si256）可以将 16 字节向量插入目标寄存器的高半部分，性能几乎不比常规 16 字节加载差。
	7.	有些指令可以绕过 CPU 缓存进行加载或存储，如 _mm[256]_stream_* 指令。这在视频处理等场景中非常有用，比如你确定数据在写入后会延迟很久才被读取，甚至由另一个 CPU 核心读取（因为 L1 和 L2 是每核私有的，只有 L3 是共享的）。
	8.	大多数现代 CPU 每个周期可执行的加载操作数量是存储操作的两倍。

⸻

向量寄存器的初始化

用零初始化

所有向量类型都提供类似 _mm_setzero_ps 和 _mm256_setzero_si256 这样的 intrinsic，用于将寄存器初始化为全零。这类指令最终会被编译成类似：

xorps xmm0, xmm0

的汇编指令。
这种零初始化的方式非常高效，因为 XOR 指令没有操作数依赖，CPU 只需将一个新寄存器重命名即可[^5]。

⸻

用特定值初始化

CPU 本身无法直接用除 0 以外的常量初始化寄存器，但编译器会模拟出这样的效果，通过以下几类 intrinsic 提供支持：
	•	_mm[256]_set_*：用于为每个通道设置不同的值；
	•	_mm[256]_set1_*：用于将所有通道设置为同一个值。

如果这些参数是编译期常量，编译器通常会将它们作为只读数据嵌入二进制中，并确保数据是对齐的，整个 16/32 字节的常量都会被一次性加载。

如果参数不是编译期常量，编译器会采用其他合理的策略，例如：
	•	如果目标寄存器大部分为 0，只设置一个通道，那么可能会用 _mm_insert_* 类指令；
	•	如果值来自变量，编译器可能会用混合（shuffle）、标量存储再加向量加载等方式构造结果。

值得一提的是，Intel 在所有 _mm[256]_set_* intrinsic 的通道顺序上搞砸了：

如果你想创建一个包含整数 [1, 2, 3, 4] 的寄存器，写法必须是：

_mm_set_epi32(4, 3, 2, 1)  // 倒序

或者使用：

_mm_setr_epi32(1, 2, 3, 4)  // r 表示 reverse，对应正常顺序


⸻

位操作指令（Bitwise Instructions）

无论是浮点数还是整数，SIMD 都提供了一套完整的位操作指令，包括：
	•	与（AND）
	•	或（OR）
	•	异或（XOR）
	•	与非（ANDNOT）

如果你需要执行**按位取反（NOT）**操作，最快的方式通常是将数据与全 1 进行异或。下面是一个对 16 字节整数向量执行按位取反的示例：

__m128i bitwiseNot(__m128i x)
{
    const __m128i zero = _mm_setzero_si128();
    const __m128i one = _mm_cmpeq_epi32(zero, zero);  // 全 1
    return _mm_xor_si128(x, one);
}

当你需要一个“所有位都为 1”的寄存器时，常见做法是先 _mm_setzero_si128()，然后与自己比较生成全 1 值，就像上面这样。

⸻

[^5]: 因为 XOR 同一寄存器不会有数据依赖，现代 CPU 可通过寄存器重命名优化执行路径，非常高效。

⸻

浮点指令

算术运算

大多数浮点指令都同时提供全通道版本和单通道版本。
单通道版本只对一个通道执行计算，其余通道直接从第一个操作数复制过来。

⸻

常规操作

四则运算（加、减、乘、除）都被实现了，连平方根指令也有，并且支持 64 位浮点数。

⸻

非常规操作

CPU 提供了**最小值（min）和最大值（max）**指令。现代编译器通常会将标准库函数 std::min<float> / std::max<double> 编译为 _mm_min_ss / _mm_max_sd。

对于 32 位浮点数，CPU 还实现了1/x 和 1/√x 的快速近似指令，分别是：
	•	_mm_rcp_ps：倒数（Reciprocal）
	•	_mm_rsqrt_ps：倒数开方（Reciprocal Square Root）

文档指出，这些近似值的最大相对误差小于 1.5 × 2^-12，即大约 3.6621 × 10⁻⁴ 的最大相对误差。

SSE3 引入了水平加法与减法指令，例如 _mm_hadd_ps，它接受两个寄存器 [a, b, c, d] 和 [e, f, g, h]，返回 [a+b, c+d, e+f, g+h]。不过性能不算太好。

SSE3 还包括一些交替加减的指令，例如 _mm_addsub_ps：输入 [a, b, c, d] 和 [e, f, g, h]，输出为 [a-e, b+f, c-g, d+h]。_mm_addsub_pd 也是类似操作，但用于双精度。
这类操作在复数乘法等场景中非常实用。

SSE4.1 引入了点积（dot product）指令，接收两个寄存器和一个 8 位常量。这个常量的高 4 位指定参与点积的输入通道，低 4 位决定哪些通道存储点积结果。

例如，在开启 SSE4.1 的情况下，DirectX 的 XMVector3Dot 函数会被编译为一条指令：

_mm_dp_ps(a, b, 0b01111111)

这个常量的含义是：对前 3 个通道计算点积，忽略最高通道的输入，将结果广播到所有输出通道。常量中低 4 位为 0 的通道会被设为 0.0f。

SSE4.1 还添加了舍入指令，支持 32 位和 64 位浮点数。32 位浮点数的全通道版本在 C++ 中暴露为：
	•	_mm_round_ps：四舍五入
	•	_mm_ceil_ps：向上取整
	•	_mm_floor_ps：向下取整

而在 AVX 中，Intel 并未提供对应的 _mm256_ceil_ps 或 _mm256_floor_ps，只提供了 _mm256_round_ps 和 _mm256_round_pd，并通过额外的整数参数指定舍入方式：
	•	_MM_FROUND_NINT：四舍五入
	•	_MM_FROUND_FLOOR：向负无穷取整
	•	_MM_FROUND_CEIL：向正无穷取整
	•	_MM_FROUND_TRUNC：向零截断

⸻

缺失的指令

与 ARM 的 NEON 不同，SSE 并没有提供一元负号或绝对值的指令。最快的实现方式是使用按位操作技巧：
	•	一元负号（取负）：

_mm_xor_ps(x, _mm_set1_ps(-0.0f))


	•	绝对值（取正）：

_mm_andnot_ps(_mm_set1_ps(-0.0f), x)



为什么这能起作用？因为 -0.0f 在 IEEE 754 格式中只有符号位为 1，其余全是 0。因此：
	•	XOR 可以翻转符号位，相当于取负；
	•	ANDNOT 可以清除符号位，相当于取绝对值。

此外，SSE 并不提供 log、exp、sin、cos 等数学函数的指令。虽然 Intel 的文档中提到这些函数，但那是因为他们指的是自家 C++ 编译器标准库中的实现，而不是硬件指令。

你可以回退到标量代码，或者更好地上网搜索实现方式。这些函数的实现并不算复杂，通常使用高阶极小极大（minmax）多项式逼近算法。
	•	对于 单精度 浮点数，可以使用 DirectXMath 中的 XMVectorSin / XMVectorCos 等函数；
	•	对于 双精度 浮点数，可以参考 Geometric Tools 中的多项式系数实现。

⸻

比较操作

SIMD 提供了支持**所有通道（all-lanes）**的比较指令，包括：
	•	相等（==）
	•	小于（<）
	•	大于（>）
	•	小于等于（≤）
	•	大于等于（≥）
	•	不等于（≠）

这些比较操作返回另一个浮点向量寄存器，其每个通道的值要么是全零（0.0f），要么是所有位为 1的浮点值。值得注意的是：所有位为 1 的 float 实际上是一个 NaN（非数）值。

⸻

将比较结果转为 CPU 标量寄存器

你可以使用 _mm_movemask_ps、_mm_movemask_pd（或对应的 AVX1 版本）把比较结果从向量寄存器转移到通用 CPU 寄存器中。

这些指令会从每个 float 或 double 通道中提取最高有效位（MSB）——实际上这通常是符号位，然后将它们打包为一个标量整数，放入普通寄存器。

例如，下面的代码会打印出 15：

const __m128 zero = _mm_setzero_ps();
const __m128 eq = _mm_cmpeq_ps(zero, zero);
const int mask = _mm_movemask_ps(eq);
printf("%i\n", mask);

解释：
	•	0 == 0 成立，因此 __m128 中的 4 个通道的结果都是 “真”，即所有位为 1；
	•	eq 变量因此是全 1（128 位）；
	•	_mm_movemask_ps 提取 4 个通道的符号位（MSB），得出二进制 0b1111，对应十进制 15。

⸻

用比较结果做更多操作

比较结果本质上是一个按位掩码（mask），你可以：
	•	将其用于位运算（如与/或/异或），以组合通道；
	•	将其传入 blendv_* 函数，实现按掩码选择数据；
	•	或者直接转换为整数向量，再进行其他处理。

⸻

比较单个通道（低位通道）

对于 32 位和 64 位浮点数，SSE 提供了只比较两个寄存器第一个通道（最低通道）的指令，并将结果作为布尔值写入 CPU 标志寄存器（flags），以便用于普通指令判断。

例如，下面的代码检查 x 的第一个通道是否大于 0：

bool isFirstLanePositive(__m128 x)
{
    return (bool)_mm_comigt_ss(x, _mm_setzero_ps());
}


⸻

AVX 比较指令

在 AVX 中，Intel 只定义了两个比较指令：
	•	_mm256_cmp_ps：用于 32 位浮点向量比较
	•	_mm256_cmp_pd：用于 64 位浮点向量比较

它们接受一个额外的整数常量作为比较谓词（predicate），如：
	•	_CMP_EQ_OQ：等于
	•	_CMP_LT_OS：小于
	•	_CMP_GE_OQ：大于等于
等（可以在 <immintrin.h> 中找到更多定义）

想了解各种谓词的具体含义，可以参考 StackOverflow 上这篇解答：
👉 https://stackoverflow.com/questions/14733950/what-do-the-parameters-to-mm-cmp-ps-mean

⸻

洗牌（Shuffle）

洗牌指令用于重新排列寄存器中的各个通道（lane），这可能是 SIMD 中最复杂的主题之一。
下面是一个转置 4×4 矩阵的示例代码，对我来说虽然理解，但看起来有点复杂和吓人。

⸻

以 32 位浮点数为例的洗牌指令

以 16 字节寄存器中 32 位浮点数通道的洗牌为例，以下图示中：
	•	左边的方框表示输入寄存器的通道；
	•	右边的方框表示输出寄存器的通道；
	•	通道用 A、B、C、D 表示，第一个通道位于顶部。

⸻

编译时常量控制的洗牌

这类洗牌指令的控制参数是编译时常量（compile-time constant），也就是说参数必须是编译期确定的，如 C++ 的 constexpr 或模板参数。

如果你尝试传入运行时动态值，编译器会报错，比如：

const __m128 zero = _mm_setzero_ps();
return _mm_shuffle_ps(zero, zero, rand()); // 错误，rand()不是编译时常量

VC++ 编译器会提示：

error C2057: expected constant expression


⸻

图示说明

下图中，蓝色箭头表示本次控制常量选择了哪些通道。
虚线灰色箭头表示其他可能由不同控制常量选择的通道。

⸻

对 64 位浮点数和 AVX 的情况
	•	对于 __m128d（64 位浮点的 128 位寄存器）和 AVX 的 __m256 / __m256d，Intel 设计得和 32 位浮点很类似，洗牌常量只用了较少的位数（因为通道数少了），思路完全相同。
	•	AVX 32 字节（256 位）寄存器中的 _mm256_shuffle_ps 等指令只能在 128 位半寄存器内进行洗牌，不会跨越 128 位边界。文档原话是：
Shuffle single-precision (32-bit) floating-point elements in “a” within 128-bit lanes.
	•	但 AVX2 新增了一些可以跨 16 字节通道边界洗牌的指令：
	•	_mm256_broadcastss_ps：广播最低通道的单精度浮点数到 8 个通道。
	•	_mm256_broadcastsd_pd：广播最低通道的双精度浮点数到所有通道。
	•	_mm256_permute2f128_ps、_mm256_permute2f128_pd、_mm256_permute2x128_si256：在两个 256 位寄存器之间交换或混合 128 位半寄存器，也可以选择性清零某些 128 位半寄存器。
	•	_mm256_permute4x64_pd 和 _mm256_permute4x64_epi64：对 32 字节寄存器内的 8 字节通道进行排列。

⸻

额外内容（FMA 相关，原文有重叠）

最后一段提到**FMA（融合乘加）**指令，它们精度更高、性能表现优秀，但存在一定延迟。此部分与洗牌无关，若需要我可以单独翻译。

⸻

运行时可变洗牌

SSE 4.1 引入了 _mm_blendv_ps 指令。它有三个参数，使用掩码寄存器中每个通道的符号位来选择来自寄存器 A 还是寄存器 B 的对应通道值。

SSE 系列中没有支持运行时动态控制的浮点洗牌指令。最接近的是 SSSE3 中的 _mm_shuffle_epi8（整型指令部分会详细介绍）。如果确实需要，可以将浮点寄存器转换成整数寄存器，使用 _mm_shuffle_epi8，然后再转换回来[^8]。

AVX 1 终于引入了运行时可变的浮点洗牌指令 _mm_permutevar_ps，它有两个参数：
	•	一个浮点寄存器，存放源数据；
	•	一个整数向量寄存器，存放索引。

它把整数寄存器当作 32 位通道，使用每个通道低两位来选择对应的浮点源通道值。

AVX 2 的 _mm256_permutevar8x32_ps 能在完整的 32 字节寄存器中跨通道移动数据。

⸻

融合乘加（Fused Multiply-Add，FMA）

当处理器厂商吹嘘每周期能执行多少 FLOPs（浮点运算次数）时，几乎都把 FMA 指令算作 FLOPs 的主要贡献。

FMA 指令有 3 个参数，都是 32 或 64 位浮点数，分别是 a、b 和 c，它们计算表达式：

(a \times b) + c

由于这一步包含一次乘法和一次加法，营销上把它算作 2 次 FLOPs。

现代 CPU 对 32 位浮点数支持 8 路 FMA，C++ 中对应的 intrinsic 是 _mm256_fmadd_ps；对 64 位浮点数支持 4 路 FMA，intrinsic 是 _mm256_fmadd_pd。

除此之外，还有变种：
	•	用减法替代加法的版本；
	•	乘积取反后加的版本；
	•	交替加减的版本，比如偶数通道计算 (a * b) + c，奇数通道计算 (a * b) - c，或反过来。这些通常用于复数乘法。

还有更窄版本，作用于 16 字节寄存器（4 路 32 位浮点或 2 路 64 位浮点）。

这些指令操作的 SIMD 寄存器类型包括 __m128, __m128d, __m256, __m256d。

⸻

精度和性能

除了性能优势，FMA 的另一个优点是更高的计算精度。
这些指令只做一次舍入，在乘法和加法运算全部完成后再舍入，中间结果使用的是更高精度（位数加倍）。

⸻

支持情况

虽然支持广泛，但还不是完全普及。Intel 和 AMD 自 2012-2013 年起发布的 CPU 支持兼容的 FMA 版本，称为 FMA3。更多硬件支持细节可参考相关硬件支持章节。

⸻

延迟问题及优化建议

FMA 指令的延迟较长，现代 CPU 需要大约 4-5 个周期。
如果你在循环里计算点积或类似操作，且循环体内累加器有数据依赖链，那么循环吞吐会被限制在 4-5 周期/次。

解决办法是：
	•	将循环展开（unroll）4 倍；
	•	使用 4 个独立累加器并行更新；
	•	循环结束后再将这 4 个累加器结果合并。

这样，每次循环迭代处理 4 个向量，能充分利用 CPU 吞吐能力，避免因数据依赖造成的流水线停顿。

你可以参考这篇 StackOverflow 回答里的示例代码，了解如何高效计算两个单精度浮点向量的点积。

⸻

这两个指令可能是最奇特的：
_mm_sad_epu8（SSE2）和 _mm256_sad_epu8（AVX2）。

在 Intel Skylake 上，这条指令每个周期可以执行一次，其功能等价于下面这段代码：

array<uint64_t, 4> avx2_sad_epu8(array<uint8_t, 32> a, array<uint8_t, 32> b)
{
    array<uint64_t, 4> result;
    for (int i = 0; i < 4; i++)
    {
        uint16_t totalAbsDiff = 0;
        for (int j = 0; j < 8; j++)
        {
            const uint8_t va = a[i * 8 + j];
            const uint8_t vb = b[i * 8 + j];
            const int absDiff = abs((int)va - (int)vb);
            totalAbsDiff += (uint16_t)absDiff;
        }
        result[i] = totalAbsDiff;
    }
    return result;
}


⸻

我猜这个指令是专门为视频编码器设计的。
显然，视频编码器把 AVX2 寄存器看作一个 8×4 的灰度图像块，每个像素用 8 位表示，
然后用它来估算压缩误差。

该指令计算图像块每一行的误差绝对值和。

我也用过它几次，跟视频编码没关系，只是为了快速计算字节的和：
用全零向量作为 _mm_sad_epu8 的第二个参数，然后用 _mm_add_epi64 累加结果，这是计算字节和最快的方法之一。

⸻

比较操作
	•	只实现了全通道版本。结果与浮点比较类似，会把对应通道全部置零或全部置一。
例如，_mm_cmpgt_epi8 会根据对应的带符号 8 位整数是否大于比较值，把输出通道设置为 0 或 0xFF。
	•	小提示：所有位都为 1 的带符号整数等于 -1。
用比较结果做整数减法，可以方便统计满足条件的元素个数：

const __m128i cmp = _mm_cmpgt_epi32(val, threshold);  // val > threshold
acc = _mm_sub_epi32(acc, cmp);  // 条件成立时累加器加一

	•	注意整数溢出问题。对于 32 位计数，一般不成问题（超过 40 亿次累加才溢出）；但对于 8 和 16 位要非常小心。
常见做法是用嵌套循环，内层批量处理保证不会溢出，外层循环升级到更宽的整数通道。
	•	没有无符号整数的比较指令。如果需要，可以用带符号比较配合异或翻转最高位来模拟无符号比较，例如：

// 比较 uint16_t a > b
__m128i cmpgt_epu16(__m128i a, __m128i b)
{
    const __m128i highBit = _mm_set1_epi16((short)0x8000);
    a = _mm_xor_si128(a, highBit);
    b = _mm_xor_si128(b, highBit);
    return _mm_cmpgt_epi16(a, b);
}

	•	比较 a <= b 的简便方法（两条指令）是：min(a,b) == a。
	•	movemask 指令只对 8 位通道实现。如果想把 32 位比较结果转到通用寄存器的低位，可以先把 __m128i 强制转换为浮点类型，再用 _mm_movemask_ps，64 位同理用 _mm_movemask_pd。

⸻

移位操作

整寄存器移位
	•	只能以字节为单位移位。
	•	SSE2 指令 _mm_srli_si128 和 _mm_slli_si128 实现整体寄存器的字节右移和左移。
	•	AVX2 对应的 _mm256_slli_si256 等指令对寄存器的两个 16 字节半部分分别独立移位，跨半部分移出的字节会变成 0。
	•	如果想整体移位 32 字节 AVX 寄存器，需要一些特殊技巧（可参考 StackOverflow）。
	•	SSSE3 的 _mm_alignr_epi8 指令可以把两个寄存器拼接成 32 字节临时值，整体右移指定字节数后截取低 16 字节。

单个通道移位
	•	SSE2 有固定移位量编码在指令里的版本，也有移位量由寄存器最低通道提供的版本。
	•	移位量是比特数，应用于所有通道。
	•	右移有逻辑右移（补零）和算术右移（符号扩展）两种。
	•	例如：

_mm_srli_epi16(x, 4)   // 把 0x8015 变成 0x0801
_mm_srai_epi16(x, 4)   // 把 0x8015 变成 0xF801

	•	算术右移模拟带符号除法，比如 _mm_srai_epi16(x,4) 相当于 x/16。

变长移位
	•	AVX2 新增指令，允许每个通道分别移不同的位数，移位数由另一个向量寄存器指定。
	•	对应的intrinsics 有 _mm_sllv_epi32、_mm_srlv_epi32、_mm_sllv_epi64、_mm_srlv_epi64，以及它们的 256 位版本。

⸻

打包与解包（Pack and Unpack）
	•	与浮点不同，同一数据类型的 __m128i 和 __m256i 可以包含任意数量的通道。
	•	不同指令将它们视为 8、16、32 或 64 位有符号或无符号通道。
	•	有很多指令用于打包和解包这些通道。
	•	解包指令有两种版本：
	•	unpacklo_something 从两个寄存器的低半部分解包并交织元素，比如：

_mm_unpacklo_epi32([a,b,c,d], [e,f,g,h]) => [a,e,b,f]
_mm_unpackhi_epi32([a,b,c,d], [e,f,g,h]) => [c,g,d,h]


	•	一个常见用法是把第二个参数传 0，用于把无符号 8 位整数扩展成 16 位整数。

	•	打包指令分有符号和无符号两类，且都使用饱和运算。
	•	如果不想饱和，可以先做按位与操作，屏蔽高位。
	•	例如：

_mm_packs_epi16: 把两个 16 位有符号整数寄存器打包成 8 位有符号整数，溢出部分饱和
_mm_packus_epi16: 把两个 16 位无符号整数寄存器打包成 8 位无符号整数，溢出部分饱和


	•	AVX2 之前，解包时用零扩展是把无符号整数转成更大位宽的主要方法。
	•	AVX2 引入了专门的转换指令，比如：

_mm256_cvtepu8_epi32

直接把内存中的 8 个字节转换成 8 个 32 位整数向量。

⸻

洗牌指令（Shuffles）

除了打包和解包之外，还有专门用于洗牌（重新排列）整数通道的指令。

_mm_shuffle_epi8
	•	这是 SSSE3 中的一条指令，值得单独介绍。它是 SSE 系列中唯一支持运行时变量控制的洗牌指令。
	•	它从一个向量寄存器中读取洗牌控制值，而不是像其他洗牌指令只能用编译时常量控制。

对应的 C++ 伪代码如下：

array<uint8_t, 16> shuffle_epi8(array<uint8_t, 16> a, array<uint8_t, 16> b)
{
    array<uint8_t, 16> result;
    for (int i = 0; i < 16; i++)
    {
        const uint8_t mask = b[i];
        if ((mask & 0x80) != 0)
            result[i] = 0;
        else
            result[i] = a[mask & 0xF];
    }
    return result;
}

	•	不同于代码中的循环，真实硬件上这条指令延迟仅 1 个周期，吞吐量更高（我所用机器每个时钟周期可执行 2 条）。
	•	这条指令非常实用，比如可以用第一个参数作为查找表，第二个参数作为索引，实现快速位计数（Hamming weight），有时候甚至比 CPU 的专用 POPCNT 指令还快。
	•	还有它最初设计的目的是移动字节，比如重新排列数据块。

AVX2 中的 _mm256_shuffle_epi8
	•	对应的 AVX2 版本对 256 位寄存器的每个 128 位半块独立应用上述算法。

⸻

其它杂项向量指令
	•	从向量寄存器拷贝最低通道到通用寄存器：
	•	整数：_mm_cvtsi128_si32、_mm_cvtsi128_si64
	•	反向操作：_mm_cvtsi32_si128、_mm_cvtsi64x_si128（高位清零）
	•	浮点数：_mm_cvtss_f32 从向量寄存器取出单个标量浮点数。
没有反向指令（标量转向量），通常用 _mm_set_ps 或 _mm_set1_ps 代替。编译器优化通常做得很好。
	•	提取指定通道：
	•	_mm_extract_epi16（SSE2）提取指定 16 位通道，结果放通用寄存器
	•	_mm_extract_epi8、_mm_extract_epi32、_mm_extract_epi64、_mm_extract_ps（SSE4.1）对应其它宽度
	•	特别是 _mm_extract_ps 可以从向量中提取 32 位浮点数到通用整型寄存器（如 eax）
	•	SSE4.1 的 ptest 指令族：
	•	对两个向量执行按位与运算
	•	设置 CPU 标志位以指示结果是否全零或其他条件
	•	C++ 封装为 _mm_testz_si128、_mm_testnzc_si128、_mm_test_all_zeros、_mm_test_all_ones 等
	•	SSSE3 的一些特殊整数指令：
	•	_mm_mulhrs_epi16：对带符号 16 位整数执行类似于带舍入的乘法然后右移 15 位的操作，常用于 PCM 音频音量调整
	•	_mm_sign_something：根据第二个向量对应通道的符号（-1、0、+1）来乘以第一个向量对应通道的值
	•	_mm_maddubs_epi16：相当于下面的 C++ 代码，实现带符号与无符号整数的乘法累加并饱和：

array<int16_t, 8> mad_bs(array<uint8_t, 16> a, array<int8_t, 16> b)
{
    array<int16_t, 8> result;
    for (int i = 0; i < 16; i += 2)
    {
        int p1 = (int16_t)a[i] * (int16_t)b[i];
        int p2 = (int16_t)a[i+1] * (int16_t)b[i+1];
        int sum = p1 + p2;
        sum = std::max(sum, -32768);
        sum = std::min(sum, +32767);
        result[i/2] = (int16_t)sum;
    }
    return result;
}


⸻

额外说明
	•	除了算术运算，现代 CPU 还用这些 SIMD 寄存器实现了硬件加速的 AES、SHA 等密码算法。
	•	SSE4.2 还引入了一些字符串处理指令，不过它们属于更专门的领域，本篇主要关注数值计算，不再赘述。

⸻

这段是关于 SIMD 编程的一些随机实用技巧，整理并翻译如下：

⸻

随机技巧与建议

1. 内存访问的瓶颈
	•	无论计算多快，如果数据在内存中分散，性能都会大打折扣。
	•	RAM 访问非常贵，缓存未命中（cache miss）可能损失 100-300 个 CPU 周期。
	•	各级缓存访问速度依次递增：L3 缓存约 40-50 周期，L2 缓存约 10 周期，L1 缓存访问比寄存器慢很多。
	•	尽量让数据结构符合 SIMD 访问模式。推荐使用 std::vector 或类似的容器（如 CAtlArray、eastl::vector），它们顺序访问时，CPU 的预取器（prefetcher）可以有效隐藏 RAM 延迟。
	•	如果数据稀疏，考虑将它组织成多个小的稠密块，每块大小至少是一个 SIMD 寄存器的大小。
	•	遍历链表或图时，可以尝试用 _mm_prefetch 指令提前加载下一批数据，缓解内存延迟。

2. 对齐很重要
	•	内存访问对齐是性能关键。
	•	std::vector<__m128> 通常自动对齐，但对某些类型（比如 float 数组，或 DirectX::SimpleMath::Vector3）需要自定义分配器确保对齐。
	•	自定义分配器在 Windows 和 Linux 上都有测试。

3. 利用 FP64 指令处理 FP32 成对数据
	•	对于一对 32 位浮点数，可以用针对 64 位浮点数的单条指令同时加载或存储它们，需用指针强制类型转换和 _mm_castps_pd / _mm_castpd_ps 来转换向量类型。
	•	FP64 的 shuffle 和 broadcast 指令也可以用来搬移 FP32 的两两成对数据。
	•	旧 CPU 在浮点和整数核心间传递向量有延迟，但 FP32 和 FP64 都是浮点，不同情况可灵活利用。

4. 利用现成的高性能向量库
	•	推荐学习和使用 C++ 的向量库，比如 Eigen、DirectXMath 等。它们实现了许多复杂功能，避免重复造轮子。
	•	如果喜欢深入研究，可以看看 SSE 版本的 XMVector3TransformCoordStream 源码。

5. 使用 C++ 类封装复杂 SIMD 算法
	•	对于包含几个 __m128 字段的小类，放栈上创建，且避免使用指针和引用，VC++ 编译器通常能把字段放在 SIMD 寄存器，避免内存访问，性能好。
	•	这样做还能让代码更易读、易维护。小型 std::array 或 C 数组也适用。

6. 避免函数内静态 const __m128 初始化
	•	现代 C++ 内函数内静态变量初始化是线程安全的，会引入锁和条件分支，影响性能。
	•	推荐放到全局变量中，或函数内使用非静态的 const 变量。

7. 宏定义帮助写 shuffle 常量
	•	<xmmintrin.h> 中有 _MM_SHUFFLE 宏，方便写 _mm_shuffle_ps 和 _mm_shuffle_epi32 的常量参数。

8. 32 位平台与 64 位整数寄存器指令限制
	•	32 位平台通用寄存器都是 32 位，无法用 SIMD 指令直接移动 64 位整数到通用寄存器。
	•	可用 load/store 或分两条指令分别处理两个 32 位值。

9. 强制内联提升性能
	•	在性能关键的热循环中，对 SIMD 函数加 __forceinline（VC++）效果显著，能减少常量加载，提升 20% 性能。
	•	SIMD 代码中“魔法数字”多数来自内存，内联后这些常量可常驻寄存器。
	•	64 位默认调用约定对向量参数也很好，32 位用 __vectorcall 调用约定会更快。
	•	GCC/Clang 可用宏定义模拟 __forceinline：

#define __forceinline inline __attribute__((always_inline))



10. Agner Fog 的资源
	•	Agner Fog 网站有丰富的 SIMD 优化资料，包括汇编子程序优化、指令延迟表、向量库（Apache 授权）。
	•	网址：https://www.uops.info/table.html 提供详细指令性能数据。

⸻

如果你想，我也可以帮你写示例代码，或者针对你的具体项目给出更精准的优化建议。